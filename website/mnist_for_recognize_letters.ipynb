{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOmODa0TplZZ",
        "outputId": "35caeb7d-83c1-47a4-d681-2c532598aa14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - accuracy: 0.8566 - loss: 0.4854\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - accuracy: 0.9550 - loss: 0.1526\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9667 - loss: 0.1130\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9724 - loss: 0.0901\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9781 - loss: 0.0715\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9724 - loss: 0.0885\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07625201344490051, 0.9761000275611877]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "  loss='sparse_categorical_crossentropy',\n",
        "  metrics=['accuracy', 'f1_score'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"model_test.keras\")"
      ],
      "metadata": {
        "id": "LHf_njeRpno2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflowjs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBXjlEodq8oK",
        "outputId": "9cb0aa3b-2202-49f2-df84-c37e616c4bb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflowjs\n",
            "  Downloading tensorflowjs-4.22.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: flax>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (0.10.3)\n",
            "Requirement already satisfied: importlib_resources>=5.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (6.5.2)\n",
            "Requirement already satisfied: jax>=0.4.13 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (0.4.33)\n",
            "Requirement already satisfied: jaxlib>=0.4.13 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (0.4.33)\n",
            "Requirement already satisfied: tensorflow<3,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (2.18.0)\n",
            "Requirement already satisfied: tf-keras>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (2.18.0)\n",
            "Collecting tensorflow-decision-forests>=1.5.0 (from tensorflowjs)\n",
            "  Downloading tensorflow_decision_forests-1.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: six<2,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (1.17.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.16.1 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (0.16.1)\n",
            "Collecting packaging~=23.1 (from tensorflowjs)\n",
            "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (1.26.4)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (0.2.4)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (0.6.4)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (0.1.72)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (13.9.4)\n",
            "Requirement already satisfied: typing_extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (6.0.2)\n",
            "Requirement already satisfied: treescope>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (0.1.9)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.4.13->tensorflowjs) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.11/dist-packages (from jax>=0.4.13->tensorflowjs) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.11/dist-packages (from jax>=0.4.13->tensorflowjs) (1.13.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (18.1.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (75.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (2.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (3.12.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (0.37.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from tensorflow-decision-forests>=1.5.0->tensorflowjs) (2.2.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from tensorflow-decision-forests>=1.5.0->tensorflowjs) (0.45.1)\n",
            "Collecting wurlitzer (from tensorflow-decision-forests>=1.5.0->tensorflowjs)\n",
            "  Downloading wurlitzer-3.1.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting ydf (from tensorflow-decision-forests>=1.5.0->tensorflowjs)\n",
            "  Downloading ydf-0.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<3,>=2.13.0->tensorflowjs) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<3,>=2.13.0->tensorflowjs) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<3,>=2.13.0->tensorflowjs) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<3,>=2.13.0->tensorflowjs) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<3,>=2.13.0->tensorflowjs) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<3,>=2.13.0->tensorflowjs) (2025.1.31)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1->flax>=0.7.2->tensorflowjs) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1->flax>=0.7.2->tensorflowjs) (2.18.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<3,>=2.13.0->tensorflowjs) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<3,>=2.13.0->tensorflowjs) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<3,>=2.13.0->tensorflowjs) (3.1.3)\n",
            "Requirement already satisfied: chex>=0.1.87 in /usr/local/lib/python3.11/dist-packages (from optax->flax>=0.7.2->tensorflowjs) (0.1.89)\n",
            "Requirement already satisfied: etils[epy] in /usr/local/lib/python3.11/dist-packages (from optax->flax>=0.7.2->tensorflowjs) (1.12.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->flax>=0.7.2->tensorflowjs) (1.6.0)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->flax>=0.7.2->tensorflowjs) (4.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->tensorflow-decision-forests>=1.5.0->tensorflowjs) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->tensorflow-decision-forests>=1.5.0->tensorflowjs) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->tensorflow-decision-forests>=1.5.0->tensorflowjs) (2025.1)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow<3,>=2.13.0->tensorflowjs)\n",
            "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chex>=0.1.87->optax->flax>=0.7.2->tensorflowjs) (0.12.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax>=0.7.2->tensorflowjs) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<3,>=2.13.0->tensorflowjs) (3.0.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.7.2->tensorflowjs) (2024.10.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.7.2->tensorflowjs) (3.21.0)\n",
            "Downloading tensorflowjs-4.22.0-py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.1/89.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_decision_forests-1.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wurlitzer-3.1.1-py3-none-any.whl (8.6 kB)\n",
            "Downloading ydf-0.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wurlitzer, protobuf, packaging, ydf, tensorflow-decision-forests, tensorflowjs\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.6\n",
            "    Uninstalling protobuf-4.25.6:\n",
            "      Successfully uninstalled protobuf-4.25.6\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "Successfully installed packaging-23.2 protobuf-5.29.3 tensorflow-decision-forests-1.11.0 tensorflowjs-4.22.0 wurlitzer-3.1.1 ydf-0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Python\n",
        "\n",
        "import tensorflowjs as tfjs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "A-t7RtwOqcot",
        "outputId": "07c957cc-7f20-452b-ffec-ebc0a854e140"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<p style=\"margin:0px;\">🌲 Try <a href=\"https://ydf.readthedocs.io/en/latest/\" target=\"_blank\">YDF</a>, the successor of\n",
              "    <a href=\"https://www.tensorflow.org/decision_forests\" target=\"_blank\">TensorFlow\n",
              "        Decision Forests</a> using the same algorithms but with more features and faster\n",
              "    training!\n",
              "</p>\n",
              "<div style=\"display: flex; flex-wrap: wrap; margin:5px;max-width: 880px;\">\n",
              "    <div style=\"flex: 1; border-radius: 10px; background-color: F0F0F0; padding: 5px;\">\n",
              "        <p\n",
              "            style=\"font-weight: bold; margin:0px;text-align: center;border-bottom: 1px solid #C0C0C0;margin-bottom: 4px;\">\n",
              "            Old code</p>\n",
              "        <pre style=\"overflow-wrap: anywhere; overflow: auto; margin:0px;font-size: 9pt;\">\n",
              "import tensorflow_decision_forests as tfdf\n",
              "\n",
              "tf_ds = tfdf.keras.pd_dataframe_to_tf_dataset(ds, label=\"l\")\n",
              "model = tfdf.keras.RandomForestModel(label=\"l\")\n",
              "model.fit(tf_ds)\n",
              "</pre>\n",
              "    </div>\n",
              "    <div style=\"width: 5px;\"></div>\n",
              "    <div style=\"flex: 1; border-radius: 10px; background-color: F0F0F0; padding: 5px;\">\n",
              "        <p\n",
              "            style=\"font-weight: bold; margin:0px;text-align: center;border-bottom: 1px solid #C0C0C0;margin-bottom: 4px;\">\n",
              "            New code</p>\n",
              "        <pre style=\"overflow-wrap: anywhere; overflow: auto; margin:0px;font-size: 9pt;\">\n",
              "import ydf\n",
              "\n",
              "model = ydf.RandomForestLearner(label=\"l\").train(ds)\n",
              "</pre>\n",
              "    </div>\n",
              "</div>\n",
              "<p style=\"margin:0px;font-size: 9pt;\">(Learn more in the <a\n",
              "        href=\"https://ydf.readthedocs.io/en/latest/tutorial/migrating_to_ydf/\" target=\"_blank\">migration\n",
              "        guide</a>)</p>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfjs.converters.save_keras_model(model, \"model_test2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NgfiTJAq7TR",
        "outputId": "dbf10c01-21ee-424f-80a8-da8f9d9221be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "failed to lookup keras version from the file,\n",
            "    this is likely a weight only file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(tfjs.converters.save_keras_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAEiJz3mrHtj",
        "outputId": "525aabc9-b1a2-4611-9fd5-a74659f4dd38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function save_keras_model in module tensorflowjs.converters.keras_h5_conversion:\n",
            "\n",
            "save_keras_model(model, artifacts_dir, quantization_dtype_map=None, weight_shard_size_bytes=4194304, metadata=None)\n",
            "    Save a Keras model and its weights in TensorFlow.js format.\n",
            "    \n",
            "    Args:\n",
            "      model: An instance of `keras.Model`.\n",
            "      artifacts_dir: The directory in which the artifacts will be saved.\n",
            "        The artifacts to be saved include:\n",
            "          - model.json: A JSON representing the model. It has the following\n",
            "            fields:\n",
            "            - 'modelTopology': A JSON object describing the topology of the model,\n",
            "              along with additional information such as training. It is obtained\n",
            "              through calling `model.save()`.\n",
            "            - 'weightsManifest': A TensorFlow.js-format JSON manifest for the\n",
            "              model's weights.\n",
            "          - files containing weight values in groups, with the file name pattern\n",
            "            group(\\d+)-shard(\\d+)of(\\d+).\n",
            "        If the directory does not exist, this function will attempt to create it.\n",
            "      quantization_dtype_map: (Optional) A mapping from dtype\n",
            "        (`uint8`, `uint16`, `float16`) to weights names. The weight mapping\n",
            "        supports wildcard substitution.\n",
            "      weight_shard_size_bytes: Shard size (in bytes) of the weight files.\n",
            "        The size of each weight file will be <= this value.\n",
            "      metadata: User defined metadata map.\n",
            "    \n",
            "    Raises:\n",
            "      ValueError: If `artifacts_dir` already exists as a file (not a directory).\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx skl2onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 705
        },
        "id": "ajdpGTFSv8AC",
        "outputId": "2ed0baa6-2e11-40ed-b3f2-8e2c784676cb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting skl2onnx\n",
            "  Downloading skl2onnx-1.18.0-py2.py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from onnx) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx) (4.25.6)\n",
            "Requirement already satisfied: scikit-learn>=1.1 in /usr/local/lib/python3.11/dist-packages (from skl2onnx) (1.6.1)\n",
            "Collecting onnxconverter-common>=1.7.0 (from skl2onnx)\n",
            "  Downloading onnxconverter_common-1.14.0-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxconverter-common>=1.7.0->skl2onnx) (24.2)\n",
            "Collecting protobuf>=3.20.2 (from onnx)\n",
            "  Downloading protobuf-3.20.2-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1->skl2onnx) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1->skl2onnx) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1->skl2onnx) (3.5.0)\n",
            "Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading skl2onnx-1.18.0-py2.py3-none-any.whl (300 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.3/300.3 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxconverter_common-1.14.0-py2.py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.20.2-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, onnx, onnxconverter-common, skl2onnx\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.6\n",
            "    Uninstalling protobuf-4.25.6:\n",
            "      Successfully uninstalled protobuf-4.25.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.2 which is incompatible.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.2 which is incompatible.\n",
            "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed onnx-1.17.0 onnxconverter-common-1.14.0 protobuf-3.20.2 skl2onnx-1.18.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "0e9195932ebe453cb164ee10ce2d1c20"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import onnx\n",
        "import joblib\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from skl2onnx import convert_sklearn\n",
        "from skl2onnx.common.data_types import FloatTensorType\n",
        "\n",
        "# Charger le dataset MNIST\n",
        "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
        "X, y = mnist.data, mnist.target.astype(np.int32)\n",
        "\n",
        "# Normaliser les données\n",
        "X = X / 255.0\n",
        "\n",
        "# Séparer en ensemble d'entraînement et de test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Entraîner un modèle Random Forest\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Évaluer le modèle\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Sauvegarder le modèle en ONNX\n",
        "initial_type = [('float_input', FloatTensorType([None, X.shape[1]]))]\n",
        "onnx_model = convert_sklearn(clf, initial_types=initial_type)\n",
        "\n",
        "# Sauvegarde du modèle ONNX\n",
        "onnx_model_path = \"random_forest_mnist.onnx\"\n",
        "with open(onnx_model_path, \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())\n",
        "\n",
        "print(f'Modèle ONNX sauvegardé sous: {onnx_model_path}')\n"
      ],
      "metadata": {
        "id": "AJn1fv-yrTRU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4b3cf2f-e805-4cb0-902d-5fb39faa52d0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9675\n",
            "Modèle ONNX sauvegardé sous: random_forest_mnist.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import onnx\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skl2onnx import convert_sklearn\n",
        "from skl2onnx.common.data_types import FloatTensorType\n",
        "\n",
        "# Charger MNIST\n",
        "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
        "X, y = mnist.data / 255.0, mnist.target.astype(int)\n",
        "\n",
        "# Division des données\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Modèle Random Forest léger\n",
        "clf = RandomForestClassifier(n_estimators=10, max_depth=10, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Conversion en ONNX\n",
        "onnx_model = convert_sklearn(clf, initial_types=[('float_input', FloatTensorType([None, X.shape[1]]))])\n",
        "\n",
        "# Sauvegarde du modèle\n",
        "with open(\"random_forest_mnist_light.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())\n",
        "\n",
        "print(\"Modèle ONNX light sauvegardé.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-dIe4t4v489",
        "outputId": "c1bfbb99-8972-4cb4-9d6f-6547d9635ed8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modèle ONNX sauvegardé.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPobeAhw0Lu5",
        "outputId": "9da9bb7a-8094-4e6b-d95f-972d60f48793"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9253\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(clf.predict(X_test[:1]))  # Vérifie la sortie en Sklearn\n",
        "print(onnx_model.graph.output)  # Vérifie la sortie en ONNX\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOj8mZxx05IP",
        "outputId": "99641846-bc06-4d7c-f86c-741ab0690632"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8]\n",
            "[name: \"output_label\"\n",
            "type {\n",
            "  tensor_type {\n",
            "    elem_type: 7\n",
            "    shape {\n",
            "      dim {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", name: \"output_probability\"\n",
            "type {\n",
            "  sequence_type {\n",
            "    elem_type {\n",
            "      map_type {\n",
            "        key_type: 7\n",
            "        value_type {\n",
            "          tensor_type {\n",
            "            elem_type: 1\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AL71HFkS20DZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}